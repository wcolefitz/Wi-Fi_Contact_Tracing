{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb #if this doesn't work, run 'pip install import-ipynb'\n",
    "\n",
    "from Algorithms_Functions import *\n",
    "from Join_Functions import *\n",
    "from import_script_master import *\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analyze(initials, test_num_start, test_num_stop, interval, algorithm):\n",
    "    '''Prints and exports (as CSV file) value from specified algorithm and Wi-Fi scans\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    initials : list of strings\n",
    "        list of 2 initials indicating devices to compare\n",
    "    \n",
    "    test_num_start : int\n",
    "        starting scan to compare\n",
    "            \n",
    "    test_num_stop : int\n",
    "        ending test to compare\n",
    "    \n",
    "    interval : int\n",
    "        comparison interval in seconds\n",
    "    \n",
    "    algorithm : object\n",
    "        algorithm to use\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    vals : list of floats\n",
    "        list of algorithm results\n",
    "    '''\n",
    "    \n",
    "    joined={}\n",
    "    \n",
    "    #different join function is used depending on algorithm\n",
    "    if algorithm==calculate_mu_universal or algorithm==euc_distance:\n",
    "        for i in range(test_num_start, test_num_stop+1):\n",
    "            joined[i]=join_master(initials, i, interval)\n",
    "    else:\n",
    "        for i in range(test_num_start, test_num_stop+1):\n",
    "            joined[i]=join_master_unmatched(initials, i, interval)\n",
    "    \n",
    "    vals={}\n",
    "    test_nums=[]\n",
    "    euc_dists=[]\n",
    "    \n",
    "    #iterate through lists of joined tables\n",
    "    for i in range(test_num_start,test_num_stop+1):\n",
    "        list_tables=joined.get(i)\n",
    "        list_1=[]\n",
    "        \n",
    "        #iterate through joined tables within list, apply specified algorithm and append results to a list\n",
    "        for j in list_tables:\n",
    "            list_1.append(algorithm(j))\n",
    "            test_nums.append(i)\n",
    "            euc_dists.append(algorithm(j))\n",
    "        vals[i]=list_1\n",
    "    \n",
    "    #put test numbers and corresponding euclidian distances (or other algorithm result) into a dictionary\n",
    "    d={'test_num':test_nums, 'euc_dist':euc_dists}\n",
    "    df= pd.DataFrame(data=d)\n",
    "    \n",
    "    #export data to a CSV file\n",
    "    df.to_csv(str(algorithm) +', ' + str(test_num_start) + \"-\" + str(test_num_stop) + '.csv' )\n",
    "    \n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD COMMENTS\n",
    "def Analyze_and_Plot_threshold(initials, test_num_start, test_num_stop, interval, algorithm, true_dist, path, export, threshold, subject_of_test, joined, pri_obs):\n",
    "    '''Prints and exports (as png file) plot of algorithm result vs true distance, exports a variety of test statistics into CSV files indicating the accuracy of the algorithm/threshold used. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    initials : list of strings\n",
    "        list of 2 initials indicating devices to compare\n",
    "    \n",
    "    test_num_start : int\n",
    "        starting scan to compare\n",
    "            \n",
    "    test_num_stop : int\n",
    "        ending test to compare\n",
    "    \n",
    "    interval : int\n",
    "        comparison interval in seconds\n",
    "    \n",
    "    algorithm : object\n",
    "        algorithm to use\n",
    "        \n",
    "    true_dist : list of ints\n",
    "        list of true distances, in order that scans were recorded\n",
    "        \n",
    "    path : str\n",
    "        not used currently\n",
    "        \n",
    "    export : bool\n",
    "        save plots as png files?\n",
    "        \n",
    "    threshold : int\n",
    "        threshold to test in desired algorithm\n",
    "        \n",
    "    subject_of_test : str\n",
    "        subject of test for file naming purposes\n",
    "        \n",
    "    joined : list of dfs\n",
    "        list of joined dfs\n",
    "    \n",
    "    pri_obs : str\n",
    "        initials of primary observer, only relevant if algorithm is calculate_mu or calculate_mu_modifies\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    vals : float\n",
    "        value of the algorithm calculation\n",
    "    \n",
    "    average_percentage_error : float\n",
    "        average percentage error for the line of best fit\n",
    "    \n",
    "    threshold : float\n",
    "        threshold\n",
    "    \n",
    "    a : float\n",
    "        y-intercept\n",
    "    \n",
    "    b : float\n",
    "        slope\n",
    "    \n",
    "    r2 : float\n",
    "        r^2 value for the line of best fit\n",
    "    \n",
    "    ss_res_over_n : float\n",
    "    \n",
    "    ss_res_over_nm : float\n",
    "    \n",
    "    res_over_tot_over_m : float\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    vals={}\n",
    "    x_1=[]\n",
    "    y_1=[]\n",
    "    true_dist_counter=[]\n",
    "    for i in range(test_num_start,test_num_stop+1):\n",
    "        table=joined.get(i)\n",
    "        list_1=[]\n",
    "        true_dist_counter.append(len(table))\n",
    "        for j in table:\n",
    "            if algorithm == calculate_mu_thresh or algorithm == calculate_mu_modified_thresh:\n",
    "                list_1.append(algorithm(j, pri_obs, threshold))\n",
    "            else:\n",
    "                list_1.append(algorithm(j, threshold))\n",
    "        vals[i]=list_1\n",
    "        y_1+=list_1\n",
    "    \n",
    "\n",
    "    if (test_num_stop+1)-test_num_start != len(true_dist):\n",
    "        return print('true_dist entries do not match number of tests')\n",
    "    \n",
    "    for i in range(len(true_dist)):\n",
    "        x_1+=true_dist_counter[i]*[true_dist[i]]\n",
    "    \n",
    "    \n",
    "    #model=np.polyfit(x_1, y_1, 1)\n",
    "    #predict=np.poly1d(model)\n",
    "    #r2_auto=r2_score(y_1, predict(x_1))\n",
    "    \n",
    "    #trendline\n",
    "    xbar = sum(x_1)/len(x_1)\n",
    "    ybar = sum(y_1)/len(y_1)\n",
    "    n = len(x_1)\n",
    "    numerator = sum([x_1i*y_1i for x_1i,y_1i in zip(x_1,y_1)]) - n * xbar* ybar\n",
    "    denominator = sum([x_1i**2 for x_1i in x_1]) - n * xbar**2\n",
    "    b = numerator/denominator\n",
    "    a = ybar - b * xbar\n",
    "    print(\"y-intercept\")\n",
    "    print(a)\n",
    "    print(\"slope\")\n",
    "    print(b)\n",
    "    \n",
    "    #plot stuff\n",
    "    plt.scatter(x_1,y_1)\n",
    "    yfit = [a + b * x_1i for x_1i in x_1]\n",
    "    plt.plot(x_1, yfit)\n",
    "    plt.xlabel('True Distance')\n",
    "    plt.ylabel('RSSI Euclidean Distance')\n",
    "    #plt.text(1,1,'y = ' + str(a) + 'x' + ' + ' + str(b))\n",
    "    \n",
    "    #averaged percentage error analysis\n",
    "    total_error = 0\n",
    "    for i in x_1:\n",
    "        truevalue = y_1[i]\n",
    "        calcvalue = a + b * x_1[i]\n",
    "        if calcvalue==0: ##ADDED THIS, fix?\n",
    "            individual_percentage_error=0\n",
    "        else:\n",
    "            individual_percentage_error = (truevalue - calcvalue)/(calcvalue)\n",
    "        total_error += abs(individual_percentage_error)\n",
    "    #get average of percentage error  \n",
    "    \n",
    "    \n",
    "    if len(x_1)==0:\n",
    "        average_percentage_error=0\n",
    "    else:\n",
    "        average_percentage_error = total_error/(len(x_1))\n",
    "    r2 = r2_score(y_1, yfit)\n",
    "    #adjustedr2 = 1 - (1-r2)*((len(x_1)-1)/(len(x_1)-2))\n",
    "    \n",
    "    #sum of squared errors \n",
    "    ss_res = 0\n",
    "    for i in x_1:\n",
    "        truevalue = y_1[i]\n",
    "        calcvalue = a+b*x_1[i]\n",
    "        ss_res += (truevalue - calcvalue)**2\n",
    "    \n",
    "    if len(x_1)==0 or b==0:\n",
    "        ss_res_over_n = 0\n",
    "        ss_res_over_nm = 0\n",
    "        res_over_tot_over_m=0\n",
    "    else:\n",
    "        ss_res_over_n = ss_res/len(x_1)\n",
    "        ss_res_over_nm = ss_res_over_n/b\n",
    "        res_over_tot_over_m=(1-r2)/b\n",
    "    \n",
    "    #neal_performance_stat=(r2**0.5)/b\n",
    "\n",
    "    \n",
    "    #plt.text(1, 2, \"Average Percentage Error: \" + str(average_percentage_error))\n",
    "    plt.title(str(initials) + ', tests: ' + str(test_num_start) + '-' + str(test_num_stop) + '\\n y = ' + str(b) + 'x' + ' + ' + str(a) + '\\n threshold = ' + str(threshold) + '\\n r^2 = ' + str(r2))\n",
    "\n",
    "    title = str(initials) + ', tests: ' + str(test_num_start) + '-' + str(test_num_stop) + ' ' + str(subject_of_test) + ' threshold = ' + str(threshold)     \n",
    "    if export==True:\n",
    "        plt.savefig(title+'.png', bbox_inches = \"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return vals, average_percentage_error, threshold, a, b, r2, ss_res_over_n, ss_res_over_nm, res_over_tot_over_m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD COMMENTS\n",
    "def Analyze_and_Plot(initials, test_num_start, test_num_stop, interval, algorithm, true_dist, path, export, alg_name, pri_obs, y_lab):\n",
    "    \n",
    "    '''Prints and exports (as png file) plot of algorithm result vs true distance, exports a variety of test statistics into CSV files indicating the accuracy of the algorithm used. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    initials : list of strings\n",
    "        list of 2 initials indicating devices to compare\n",
    "    \n",
    "    test_num_start : int\n",
    "        starting scan to compare\n",
    "            \n",
    "    test_num_stop : int\n",
    "        ending test to compare\n",
    "    \n",
    "    interval : int\n",
    "        comparison interval in seconds\n",
    "    \n",
    "    algorithm : object\n",
    "        algorithm to use\n",
    "        \n",
    "    true_dist : list of ints\n",
    "        list of true distances, in order that scans were recorded\n",
    "        \n",
    "    path : str\n",
    "        not used currently\n",
    "        \n",
    "    export : bool\n",
    "        save plots as png files?\n",
    "        \n",
    "    alg_name : str\n",
    "        subject of test for file naming purposes\n",
    "        \n",
    "    \n",
    "    pri_obs : str\n",
    "        initials of primary observer, only relevant if algorithm is calculate_mu or calculate_mu_modifies\n",
    "        \n",
    "    y_lab : str\n",
    "        y-axis label\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    joined={}\n",
    "    \n",
    "    if algorithm == calculate_mu or algorithm == calculate_mu_modified or algorithm == calculate_mu_universal or algorithm == euc_distance or algorithm==euc_distance_norm_1 or algorithm==euc_distance_norm_2 or algorithm==euc_distance_norm_3:\n",
    "        for i in range(test_num_start, test_num_stop+1):\n",
    "            joined[i]=join_master(initials, i, interval)\n",
    "    else:\n",
    "        for i in range(test_num_start, test_num_stop+1):\n",
    "            joined[i]=join_master_unmatched(initials, i, interval)\n",
    "\n",
    "    vals={}\n",
    "    x_1=[]\n",
    "    y_1=[]\n",
    "    true_dist_counter=[]\n",
    "    for i in range(test_num_start,test_num_stop+1):\n",
    "        table=joined[i]\n",
    "        list_1=[]\n",
    "        true_dist_counter.append(len(table))\n",
    "        for j in table:\n",
    "            if algorithm == calculate_mu or algorithm == calculate_mu_modified:\n",
    "                list_1.append(algorithm(j, pri_obs))\n",
    "            else:\n",
    "                list_1.append(algorithm(j))\n",
    "        vals[i]=list_1\n",
    "        y_1+=list_1\n",
    "    \n",
    "\n",
    "    if (test_num_stop+1)-test_num_start != len(true_dist):\n",
    "        return print('true_dist entries do not match number of tests')\n",
    "    \n",
    "    for i in range(len(true_dist)):\n",
    "        x_1+=true_dist_counter[i]*[true_dist[i]]\n",
    "    \n",
    "    \n",
    "    model=np.polyfit(x_1, y_1, 1)\n",
    "    predict=np.poly1d(model)\n",
    "    #r2_auto=r2_score(y_1, predict(x_1))\n",
    "    \n",
    "    #trendline\n",
    "    xbar = sum(x_1)/len(x_1)\n",
    "    ybar = sum(y_1)/len(y_1)\n",
    "    n = len(x_1)\n",
    "    numerator = sum([x_1i*y_1i for x_1i,y_1i in zip(x_1,y_1)]) - n * xbar* ybar\n",
    "    denominator = sum([x_1i**2 for x_1i in x_1]) - n * xbar**2\n",
    "    b = numerator/denominator\n",
    "    a = ybar - b * xbar\n",
    "    print(\"y-intercept\")\n",
    "    print(a)\n",
    "    print(\"slope\")\n",
    "    print(b)\n",
    "    \n",
    "    #plot stuff\n",
    "    plt.scatter(x_1,y_1)\n",
    "    yfit = [a + b * x_1i for x_1i in x_1]\n",
    "    plt.plot(x_1, yfit)\n",
    "    plt.xlabel('True Distance')\n",
    "    plt.ylabel(y_lab)\n",
    "    #plt.text(1,1,'y = ' + str(a) + 'x' + ' + ' + str(b))\n",
    "    \n",
    "    #averaged percentage error analysis\n",
    "    total_error = 0\n",
    "    for i in x_1:\n",
    "        truevalue = y_1[i]\n",
    "        calcvalue = a + b * x_1[i]\n",
    "        if calcvalue==0: ##ADDED THIS, fix?\n",
    "            individual_percentage_error=0\n",
    "        else:\n",
    "            individual_percentage_error = (truevalue - calcvalue)/(calcvalue)\n",
    "        total_error += abs(individual_percentage_error)\n",
    "    #get average of percentage error  \n",
    "    \n",
    "    \n",
    "    if len(x_1)==0:\n",
    "        average_percentage_error=0\n",
    "    else:\n",
    "        average_percentage_error = total_error/(len(x_1))\n",
    "    r2 = r2_score(y_1, yfit)\n",
    "    #adjustedr2 = 1 - (1-r2)*((len(x_1)-1)/(len(x_1)-2))\n",
    "    \n",
    "    #sum of squared errors \n",
    "    ss_res = 0\n",
    "    for i in x_1:\n",
    "        truevalue = y_1[i]\n",
    "        calcvalue = a+b*x_1[i]\n",
    "        ss_res += (truevalue - calcvalue)**2\n",
    "    \n",
    "    if len(x_1)==0 or b==0:\n",
    "        ss_res_over_n = 0\n",
    "        ss_res_over_nm = 0\n",
    "        res_over_tot_over_m=0\n",
    "    else:\n",
    "        ss_res_over_n = ss_res/len(x_1)\n",
    "        ss_res_over_nm = ss_res_over_n/b\n",
    "        res_over_tot_over_m=(1-r2)/b\n",
    "    \n",
    "    #neal_performance_stat=(r2**0.5)/b\n",
    "\n",
    "    \n",
    "    #plt.text(1, 2, \"Average Percentage Error: \" + str(average_percentage_error))\n",
    "    plt.title(str(initials) + ', tests: ' + str(test_num_start) + '-' + str(test_num_stop) + '\\n y = ' + str(b) + 'x' + ' + ' + str(a) + '\\n r^2 = ' + str(r2))\n",
    "\n",
    "    title = str(initials) + ', tests: ' + str(test_num_start) + '-' + str(test_num_stop) + ' ' + alg_name  \n",
    "    if export==True:\n",
    "        plt.savefig(title+'.png', bbox_inches = \"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    d={'algorithm':[algorithm], 'slope':[b], 'y_int':[a], 'Avg_%_Error': [average_percentage_error], 'r2':[r2], 'ss_res_over_n':[ss_res_over_n], 'ss_res_over_nm':[ss_res_over_nm], 'res_over_tot_over_m':[res_over_tot_over_m]}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    print(df)\n",
    "    df.to_csv(str(initials) + ', tests: ' + str(test_num_start) + '-' + str(test_num_stop) + ' ' + alg_name+ '.csv')\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
