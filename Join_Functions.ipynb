{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFUNCTIONS:\\n\\nimport_tests\\nconvert_to_secs\\nsplit_by_interval\\ngroup_by_BSS\\njoin_tables\\njoin_master\\njoin_cos\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "FUNCTIONS:\n",
    "\n",
    "import_tests\n",
    "convert_to_secs\n",
    "split_by_interval\n",
    "group_by_BSS\n",
    "join_tables\n",
    "join_master\n",
    "join_cos\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_tests(labels, testnum):\n",
    "    '''Imports CSV files (for our purposes, 2 files) into pandas DFs\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : list of 2 strings\n",
    "        Intials/labels of desired tests, ex: ['CF', 'CB']\n",
    "    testnum : int\n",
    "        test number according to labeling      \n",
    "    \n",
    "    '''\n",
    "    output=[]\n",
    "    \n",
    "    #iterates through each user\n",
    "    for i in range(len(labels)):\n",
    "        j=labels[i]\n",
    "        #reads corresponding CSV as a Pandas DataFrame\n",
    "        exec(\"output.append(pd.read_csv('../../CSV_Files/test_%s_%s.csv'))\" %(testnum, j))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO use datetime objects, use df.apply\n",
    "def convert_to_secs(list_of_tables):\n",
    "    '''Adds a column <Seconds> to both DFs and converts Time to Seconds\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_tables : list of DFs\n",
    "        list of DFs containing Wi-Fi scans\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    list_of_tables : list of DFs\n",
    "        list of DFs containing Wi-Fi scans\n",
    "    '''\n",
    "    \n",
    "    #iterates through DataFrames\n",
    "    for i in list_of_tables:\n",
    "        \n",
    "        #creates a column called Seconds\n",
    "        i['Seconds']=0\n",
    "        \n",
    "        #iterates through row (df.apply would be much more efficient)\n",
    "        for j in range(0, len(i)):\n",
    "            total_secs=0\n",
    "            \n",
    "            #interpretates time and calculates total seconds\n",
    "            if 'PM' in i['Time'][j]:\n",
    "                time_parsed=i['Time'][j].strip(' PM').split(':')\n",
    "                tup=(int(time_parsed[0]), int(time_parsed[1]), int(time_parsed[2]))\n",
    "                total_secs=(tup[0]+12)*60*60+tup[1]*60+tup[2]\n",
    "            elif 'AM' in i['Time'][j]:\n",
    "                time_parsed=i['Time'][j].strip(' PM').split(':')   \n",
    "                tup=(int(time_parsed[0]), int(time_parsed[1]), int(time_parsed[2]))\n",
    "                total_secs=tup[0]*60*60+tup[1]*60+tup[2]\n",
    "            else:\n",
    "                time_parsed=i['Time'][j].split(':')\n",
    "                tup=(int(time_parsed[0]), int(time_parsed[1]), int(time_parsed[2]))\n",
    "                total_secs=tup[0]*60*60+tup[1]*60+tup[2]\n",
    "                \n",
    "            #sets Seconds to total number of seconds. This will be used to group tests into comparison intervals\n",
    "            i.at[j, 'Seconds']=total_secs\n",
    "            \n",
    "    return list_of_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_interval(list_of_tables, interval):\n",
    "    '''Splits both DFs into multiple DFs based on a time comparison interval: For instance, if we compare 2 5-minute tests \n",
    "       and set the chunking interval in this method to 60 seconds, we would expect that the 2 dataframes will become an output  \n",
    "       of 10 total dataframes, since each overall table will be divided up into 5 smaller ones. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_tables : list of DFs\n",
    "        list of DFs containing Wi-Fi Scans\n",
    "    interval: int\n",
    "        chosen time comparison interval in seconds \n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    output : list of DFs\n",
    "        list of DFs containing Wi-Fi Scans\n",
    "    '''\n",
    "    output=[]\n",
    "    \n",
    "    #This finds the overall starting time between both tests. For example, if one user's scan began recording at 8:00:00 \n",
    "    #and the other user's started at 8:00:04, this method finds the overall starting time for both tests, being 8:00:04 in this \n",
    "    #case, since we want to only look at overlapping scans between the two users. \n",
    "    \n",
    "    starting_seconds = [min(i['Seconds']) for i in list_of_tables]\n",
    "    start=max(starting_seconds)\n",
    "    \n",
    "    #Similar to the previous assignment, this will find the overall ending time between the two tests. For instance, if\n",
    "    #the last scan on user 1's phone was recorded at 9:00:00 and user 2's phone picked up a final scan at 9:00:05, we determine\n",
    "    #the overall ending time to be the earlier time, 9:00:00 in this case. \n",
    "    \n",
    "    ending_seconds = [max(i['Seconds']) for i in list_of_tables]\n",
    "    end=min(ending_seconds)\n",
    "    \n",
    "    #This looks through both data frames and beginning from the determined starting time, it will increment by the desired \n",
    "    #chunking interval to group the data into smaller dataframes between designated time intervals. This will follow until the \n",
    "    #determined ending time is reached.\n",
    "    \n",
    "    iterations=int((end-start)/interval)+1\n",
    "    for i in list_of_tables:\n",
    "        minimum=start\n",
    "        maximum=minimum+interval\n",
    "        for k in range(0, iterations):\n",
    "            temp = sqldf(\"SELECT * FROM i WHERE Seconds >= %s AND Seconds < %s\" %(minimum, maximum))\n",
    "            temp['Second_Index']=minimum\n",
    "            output.append(temp)\n",
    "            minimum+=interval #updadate interval\n",
    "            maximum+=interval\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_BSS(list_of_tables):\n",
    "    '''Groups the tables by BSS and Averages the RSSI values across these matching BSS's. If following the overall joining \n",
    "        method as defined below, the group_by_BSS method will be used on the dataframes that have already been separated into \n",
    "        designated time chunks. There will be an output with one BSS per row.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_tables : list of DFs\n",
    "        list of DFs containing Wi-Fi Scans\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    output : list of DFs\n",
    "        list of DFs containing Wi-Fi Scans\n",
    "    '''\n",
    "    output=[]\n",
    "    for i in list_of_tables:\n",
    "        temp=None\n",
    "        dict_temp=None\n",
    "        temp_std=None\n",
    "        temp_std_2=None\n",
    "        temp2=None\n",
    "        \n",
    "        dict_temp={}\n",
    "        temp = i\n",
    "        \n",
    "        #Line below takes standard deviation of all columns in the dataframe, so that we can \n",
    "        #eventually access the std of RSSI w.r.t. BSS groupings.\n",
    "        temp_std=i.groupby('BSS').std(ddof=1).reset_index()\n",
    "        temp_std_2=temp_std\n",
    "        for j in range(0, len(temp_std_2)):\n",
    "            dict_temp[temp_std_2.at[j, 'BSS']]=temp_std_2.at[j, 'RSSI']\n",
    "        \n",
    "        #Averages RSSI across the specific time chunks per each BSS.\n",
    "        temp2 = sqldf(\"SELECT SSID, BSS, AVG(RSSI) AS RSSI, COUNT(BSS) as BSS_Count, Channel, Time, Seconds, Second_Index, Date, Test, Phone FROM temp GROUP BY BSS\")\n",
    "        temp2['Std_dev']=0.0 #New column, sets the standard deviations in df as decimal/float values, starting at 0.0 initially for all.\n",
    "        \n",
    "        for j in range(0, len(temp2)):\n",
    "            \n",
    "            #Acesses the calculated standard deviation across the BSS's in the dictionary and resets from 0.0 above.\n",
    "            temp2.at[j, 'Std_dev']=dict_temp.get(temp2.at[j, 'BSS'])\n",
    "        temp2['Count'] = len(temp2)\n",
    "        output.append(temp2)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_tables(list_of_tables):\n",
    "    '''Joins two tables from the same time interval. This joins data together from the two different users.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_tables : list of DFs\n",
    "        list of DFs containing Wi-Fi Scans\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    list\n",
    "        a list of DFs, each that contain two tests being compared\n",
    "    '''\n",
    "    output_temp=[]\n",
    "    for i in range(0, len(list_of_tables)):\n",
    "        \n",
    "        #Compares one table to all other tables in the list.\n",
    "        for j in range(i+1, len(list_of_tables)):\n",
    "            temp1=list_of_tables[i]\n",
    "            temp2=list_of_tables[j]\n",
    "            \n",
    "            #Joins together if the important info is the same and the users are different. \n",
    "            output_temp.append(sqldf(\"SELECT A.SSID AS SSID_A, A.RSSI AS RSSI_A, A.BSS AS BSS_A, A.Time AS Time_A, A.Seconds AS Seconds_A, A.Date AS Date_A, A.Phone \\\n",
    "            AS Phone_A, A.Count AS Count_A, A.Std_dev AS Std_dev_A, B.SSID AS SSID_B, B.RSSI AS RSSI_B , B.BSS AS BSS_B, B.Time AS Time_B, B.Seconds AS Seconds_B, B.Date AS Date_B, B.Phone AS Phone_B, B.Count AS Count_B, \\\n",
    "            B.Std_dev AS Std_dev_B FROM temp1 AS A JOIN temp2 AS B ON A.SSID = B.SSID AND A.BSS = B.BSS AND \\\n",
    "            A.Channel = B.Channel AND A.Date=B.Date AND A.Second_Index=B.Second_Index AND A.Phone != B.Phone\"))\n",
    "    output=[]\n",
    "    \n",
    "    for i in output_temp:\n",
    "        #Filter out DFs that are only NaNs - due to only 1 BSS reading.\n",
    "        if i.dropna().reset_index().empty==False:\n",
    "            output.append(i.dropna().reset_index())\n",
    "    return output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_master(initials, testnum, interval):\n",
    "    '''Joins specified tests, not considering unmatched networks\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    initials : list of 2 strings\n",
    "        devices to compare between\n",
    "    testnum : int\n",
    "        test number to compare\n",
    "    interval : int\n",
    "        comparison interval\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    list\n",
    "        a list of DFs, each that contain two tests being compared\n",
    "        \n",
    "    '''\n",
    "    step_1=import_tests(initials, testnum)\n",
    "    step_2=convert_to_secs(step_1)\n",
    "    step_3=split_by_interval(step_2, interval)\n",
    "    step_4=group_by_BSS(step_3)\n",
    "    step_5=join_tables(step_4)\n",
    "    \n",
    "    return step_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This general joining method is the same as join_master w/ the exception that join_cos does NOT drop na values.\n",
    "def join_master_unmatched(initials, testnum, interval):\n",
    "    '''Joins specified tests, leaving RSSI values of unmatched networks as NaNs\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    initials : list of 2 strings\n",
    "        devices to compare between\n",
    "    testnum : int\n",
    "        test number to compare\n",
    "    interval : int\n",
    "        comparison interval\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    list\n",
    "        a list of DFs, each that contain two tests being compared\n",
    "        \n",
    "    '''\n",
    "    step_1=import_tests(initials, testnum)\n",
    "    step_2=convert_to_secs(step_1)\n",
    "    step_3=split_by_interval(step_2, interval)\n",
    "    step_4=group_by_BSS(step_3)\n",
    "    output_temp=[]\n",
    "    for i in range(0, len(step_4)):\n",
    "        for j in range(i+1, len(step_4)):\n",
    "            temp1=step_4[i]\n",
    "            temp2=step_4[j]\n",
    "            if temp1['Phone'][0] != temp2['Phone'][0] and temp1['Second_Index'][0]==temp2['Second_Index'][0] and temp1['Date'][0]==temp2['Date'][0]: #IF Scan interval is too small, throws error\n",
    "                temp3 = pd.merge(temp1,temp2,on=['BSS'],how='outer')\n",
    "                output_temp.append(temp3)\n",
    "  \n",
    "    output=[]\n",
    "    for i in output_temp:\n",
    "        if i.empty==False:\n",
    "            output.append(i)\n",
    "\n",
    "    return output\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
